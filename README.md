# Nicholas Califano
### ML/AI Portfolio

This portfolio is comprised of examples projects intended to highlight a variety of machine learning techniques and simulate a number of discussions with stakeholders. The projects are intentionally written to be a demonstration and discussion (almost like a presentation) rather than an optimized application.

The performance of these methods is often acceptable but not spectacular due to intentionally using small datasets, small models, and small compute resources (my personal computer). The goal of this portfolio is to show competency with these techniques, not state-of-the-art results. 

The comments and discussions within a notebook are at times repetitive. This is because I expect most readers will skim the notebooks rather than read them in their entirety. If someone is looking for a particular skill, they may focus on one section of one notebook. For that reason, I tried to make each section of each notebook make sense in isolation, which at times requires repetition.

### Examples
| Example          | Demonstration of:                                   | Simulated Discussions with Stakeholders   |
|------------------|-----------------------------------------------------|-------------------------------------------|
| binary_text_<br />classification.ipynb | Relevant Libraries: transformers, PyTorch <br /><br /> Model: RoBERTa <br /><br /> ML Techniques: Pretrained Embedding Model, Transformers, Regularization, Class Imbalance Mitigations <br /><br /> Other: Text Classification, Supervised Learning | - Human-in-the-loop ML for production. <br /> - Creating a cost function based on stakeholder input. <br /> - Trade-off between missed detections and false positives <br /> - Monitoring a model and pipeline in production. <br /> - Measuring a model's and pipeline's performance with sampling. <br /> - Continual Learning. | 
| llm_as_a_judge.ipynb | Relevant Libraries: Ollama, Azure OpenAI Service, aiohttp, asyncio <br /><br /> Models: Large Language Models (Llama3.2-vision, Phi4, DeepSeek-R1-Distill-Qwen-14B, and GPT-4o mini) <br /><br /> ML Techniques: Prompt Engineering, Sensitivity Analysis <br /><br /> Other: LLM-as-a-judge, Text Evaluation | - The 'best' method (accuracy, monetary/compute cost) isnâ€™t always the best at generating business value. <br /> - Building a minimum viable product quickly, then quickly iterating (Agile) enables more feedback loops and better alignment between technical staff and stakeholders. |
| multiclass_image_<br />classification.ipynb | Relevant Libraries: Tensorflow, Keras <br /><br /> Models: Convolutional Neural Networks, Pretrained ResNet18 <br /><br /> ML Techniques: Data Augmentation, Regularization, Transfer Learning <br /><br />  Other: Image Classification, Supervised Learning | - Finding a similar dataset for pretraining. <br /> - Are all errors equally as 'bad'? <br /> - Trade-off between accuracy and inference time. |
| regression_<br />analysis.ipynb | Relevant Libraries: Sklearn, Pandas <br /><br /> Model: Gradient Boosted Regression Trees <br /><br /> ML Techniques: Regression Trees, Ensemble Methods, Bagging, Boosting, Hyperparameter Search, Crossfold Validation <br /><br /> Other: Regression, Data Cleaning, Supervised Learning | - Involving Subject Matter Experts for feature engineering and data cleaning. |
| text_clustering.ipynb | Relevant Libraries: Sklearn, SentenceTransformer, googleapiclient, azure.ai, UMAP <br /><br /> Models: gte-Qwen2-7B-instruct, UMAP, DBSCAN, K-Means, TF-IDF <br /><br /> ML Techniques: Vector Search, Embedding Model, Dimensionality Reduction, Clustering, Topic Modeling <br /><br /> Other: Data Wrangling, Translation Service, YouTube Service, Unsupervised Learning | - Making sense of a broad ask <br /> - Making sense of clusters |

### Requirements
* Everything but multiclass_image_classification.ipynb will work with Python 3.12.9 and requirements.txt
* multiclass_image_classification.ipynb will work with Python 3.12.9 and requirements_tf.txt